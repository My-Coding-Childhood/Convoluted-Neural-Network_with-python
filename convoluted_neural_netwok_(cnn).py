# -*- coding: utf-8 -*-
"""Convoluted Neural Netwok (CNN)

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TH2fOe7BiUyFe6-TPRyQQjtKsMoNZC22

#NOTE: CNN is used to decode patterns...
"""

# Let us load the necessary libraries for python implementation of convoluted neural networks
import numpy as np
import tensorflow as tf
from tensorflow import keras
from keras import layers
import matplotlib.pyplot as plt
from keras.models import Model

# Lets download the datasets
num_classes = 10 #Numbers from 0-9
input_shape = (28, 28, 1) #28*28 images with single greyscale layer

#Load data and seperate into test and training
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

#Prepare Data by dividing into 255 to make the calculations easier
x_train = x_train.astype("float32") / 255
x_test = x_test.astype("float32") / 255

x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)
print(x_train.shape[0], "train samples")
print(x_test.shape[0], "test samples")

y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

#Display example images, 10, 30, 50. Can change these to see other ones.
sampleTestImages = [10, 30, 50, 123, 1234, 1235]
fig, figPlacement = plt.subplots(1, len(sampleTestImages))
examples = list(zip(sampleTestImages, figPlacement))
print('Shape of image is ', x_test[sampleTestImages[0]].shape)
for example in examples:
  example[1].imshow(tf.squeeze(x_test[example[0]], 2), cmap='gray')

# To define and build our model
# Note: we have 2 convolutional layers with 3 by 3 filers 
# relu stands for rectified linear activation unit
# softmax function is used to make final decision of classification
model = keras.Sequential(
    [
        keras.Input(shape=input_shape),
        layers.Conv2D(32, kernel_size=(3, 3), activation="relu"),
        layers.MaxPooling2D(pool_size=(2, 2)),
        layers.Conv2D(64, kernel_size=(3, 3), activation="relu"),
        layers.MaxPooling2D(pool_size=(2, 2)),
        layers.Flatten(),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation="softmax"),
    ]
)

#Show model settings
model.summary()

# To test the images
def myTestFunction(sampleTestImages):
  fig, figPlacement = plt.subplots(1, len(sampleTestImages))
  examples = list(zip(sampleTestImages, figPlacement))
  predictions = []
  for example in examples:
    example[1].imshow(tf.squeeze(x_test[example[0]], 2), cmap='gray')
    predictions.append(tf.math.argmax(model.predict(tf.expand_dims(x_test[example[0]], 0)), 1))
  print([['Prediction ' + str(i) + ': ' + str(np.array(predictions[i]))] for i in range(len(sampleTestImages))])

# Let us now predict our image (N.B. In best case we expect an accuracy of 10% because their are 10 classes)
myTestFunction(sampleTestImages = [5, 69, 111, 244, 768])
# Notice from our result that the model could not predict any of the numbers accurately, since we performed no training

#Choose training parameters and train the model (LET'S TRAIN)
batch_size = 32
epochs = 2

model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])

model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)

# Let us check our accuracy again
myTestFunction(sampleTestImages = [1, 25, 50, 100, 200, 300])
# Notice the accuracy now that we have performed training of the datasets

#What the model is looking at... Note: After first max pooling layer the machine first sees some unclear patterns. In the second convolutional layer it becomes clearer with some visible curves. In the final (and third) convolutional layer the machine is able to recognize the hand written digits
exampleNumber = 600
#We can always change the exampleNumber. The algoithm is the same
layer_outputs = [layer.output for layer in model.layers[1:7]]
activation_model = Model(inputs=model.input,outputs=layer_outputs)

activations = activation_model.predict(tf.expand_dims(x_test[exampleNumber], 0))

layer_names = []
for layer in model.layers[1:4]:
    layer_names.append(layer.name)
    
images_per_row = 16
for layer_name, layer_activation in zip(layer_names, activations):
    n_features = layer_activation.shape[-1]
    size = layer_activation.shape[1]
    n_cols = n_features // images_per_row
    display_grid = np.zeros((size * n_cols, images_per_row * size))
    for col in range(n_cols):
        for row in range(images_per_row):
            channel_image = layer_activation[0,
                                             :, :,
                                             col * images_per_row + row]
            channel_image -= channel_image.mean()
            channel_image /= channel_image.std()
            channel_image *= 64
            channel_image += 128
            channel_image = np.clip(channel_image, 0, 255).astype('uint8')
            display_grid[col * size : (col + 1) * size,
                         row * size : (row + 1) * size] = channel_image
    scale = 1. / size
    plt.figure(figsize=(scale * display_grid.shape[1],
                        scale * display_grid.shape[0]))
    plt.title(layer_name)
    plt.grid(False)
    plt.imshow(display_grid, aspect='auto', cmap='gray')